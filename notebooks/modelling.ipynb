{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_probability\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtfp\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01marviz\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maz\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import arviz as az\n",
    "\n",
    "import IPython\n",
    "\n",
    "from meridian import constants\n",
    "from meridian.data import load\n",
    "from meridian.data import test_utils\n",
    "from meridian.model import model\n",
    "from meridian.model import spec\n",
    "from meridian.model import prior_distribution\n",
    "from meridian.analysis import optimizer\n",
    "from meridian.analysis import analyzer\n",
    "from meridian.analysis import visualizer\n",
    "from meridian.analysis import summarizer\n",
    "from meridian.analysis import formatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If utils exists with the needed encoded functions\n",
    "from utils import *\n",
    "# check if GPU is available\n",
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\\\n'.format(ram_gb))\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num CPUs Available: \", len(tf.config.experimental.list_physical_devices('CPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['Unnamed: 0',\n",
    " 'Starting week',\n",
    " 'Year',\n",
    " \"UK L'Oreal Paris Haircare Offline Average Price (in pound)\",\n",
    " \"UK L'Oreal Paris Haircare Online Average Price (in pound)\",\n",
    " \"UK L'Oreal Paris Haircare Total Weigheted Promotion Distribution (%)\",\n",
    " \"UK L'Oreal Paris Haircare Total Offline Sellout Value (in pound)\",\n",
    " \"UK L'Oreal Paris Haircare Total Offline Sellout Units\",\n",
    " \"UK L'Oreal Paris Haircare Total Online Sellout Value (in pound)\",\n",
    " \"UK L'Oreal Paris Haircare Total Online Sellout Units\",\n",
    " 'Starting week.1',\n",
    " 'impressions_digital_tv',\n",
    " 'impressions_online_multiformat_ads_transaction',\n",
    " 'impressions_online_video_content_platforms',\n",
    " 'impressions_paid_search_awarenessconsideration',\n",
    " 'impressions_paid_search_transaction',\n",
    " 'impressions_social_media_awarenessconsideration',\n",
    " 'impressions_social_media_transaction',\n",
    " 'spend_digital_tv',\n",
    " 'spend_online_multiformat_ads_transaction',\n",
    " 'spend_online_video_content_platforms',\n",
    " 'spend_paid_search_awarenessconsideration',\n",
    " 'spend_paid_search_transaction',\n",
    " 'spend_social_media_awarenessconsideration',\n",
    " 'spend_social_media_transaction',\n",
    " 'Starting week.2',\n",
    " 'engagement_influencer_management',\n",
    " 'spend_influencer_management',\n",
    " 'Starting week.3',\n",
    " 'grp_traditional_tv',\n",
    " 'spend_traditional_tv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_to_columns = load.CoordToColumns(\n",
    "    time='Starting week',\n",
    "    # geo='geo',\n",
    "    # population='population',\n",
    "    kpi='recrutements_hebdo', # choose the target variable you want\n",
    "    revenu_per_kpi= \"UK L'Oreal Paris Haircare Total Online Sellout Units\",\n",
    "    controls= [\n",
    "        \"UK L'Oreal Paris Haircare Offline Average Price (in pound)\",\n",
    "        \"UK L'Oreal Paris Haircare Online Average Price (in pound)\",\n",
    "        \"UK L'Oreal Paris Haircare Total Weigheted Promotion Distribution (%)\"\n",
    "                ],\n",
    "    media= [\n",
    "        'impressions_digital_tv',\n",
    "        'impressions_online_multiformat_ads_transaction',\n",
    "        'impressions_online_video_content_platforms',\n",
    "        'impressions_paid_search_awarenessconsideration',\n",
    "        'impressions_paid_search_transaction',\n",
    "        'impressions_social_media_awarenessconsideration',\n",
    "        'impressions_social_media_transaction',\n",
    "        ],\n",
    "    media_spend=[\n",
    "        'spend_digital_tv',\n",
    "        'spend_online_multiformat_ads_transaction',\n",
    "        'spend_online_video_content_platforms',\n",
    "        'spend_paid_search_awarenessconsideration',\n",
    "        'spend_paid_search_transaction',\n",
    "        'spend_social_media_awarenessconsideration',\n",
    "        'spend_social_media_transaction',\n",
    "                ],\n",
    "    reach=['reach_tvfixe',\n",
    "                'reach_tvmobile',\n",
    "                'reach_ooh'],\n",
    "    frequency=['frequency_tvfixe',\n",
    "                    'frequency_tvmobile',\n",
    "                    'frequency_ooh']\n",
    "    rf_spend=['spend_tv_fixe',\n",
    "                'spend_tv_mobile',\n",
    "                'spend_ooh'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_to_channel={\n",
    "    'impressions_digital_tv' : 'digital_tv',\n",
    "    'impressions_online_multiformat_ads_transaction': \"multiformat_ads\",\n",
    "    'impressions_online_video_content_platforms': \"video_content_platforms\",\n",
    "    'impressions_paid_search_awarenessconsideration': \"paid_search_awareness_consideration\",\n",
    "    'impressions_paid_search_transaction': \"search_transaction\",\n",
    "    'impressions_social_media_awarenessconsideration':\"social_media_awareness_consideration\",\n",
    "    'impressions_social_media_transaction': \"social_media_transaction\",\n",
    "}\n",
    "media_spend_to_channel={\n",
    "    'spend_digital_tv': 'digital_tv',\n",
    "    'spend_online_multiformat_ads_transaction': \"multiformat_ads\",\n",
    "    'spend_online_video_content_platforms': \"video_content_platforms\",\n",
    "    'spend_paid_search_awarenessconsideration': \"paid_search_awareness_condiseration\",\n",
    "    'spend_paid_search_transaction': \"search_transactino\",\n",
    "    'spend_social_media_awarenessconsideration': \"social_media_awareness_consideration\",\n",
    "    'spend_social_media_transaction': \"social_media_transaction\",\n",
    "}\n",
    "reach_to_channel={\n",
    "            'reach_tv_fixe':'tv_fixe',\n",
    "            'reach_tv_mobile':'tv_mobile',\n",
    "            'reach_ooh':'ooh'\n",
    "            }\n",
    "frequency_to_channel={\n",
    "            'frequency_tv_fixe':'tv_fixe',\n",
    "            'frequency_tv_mobile':'tv_mobile',\n",
    "            'frequency_ooh':'ooh'\n",
    "    }\n",
    "rf_spend_to_channel={\n",
    "            'spend_tv_fixe':'tv_fixe',\n",
    "    'spend_tv_mobile':'tv_mobile',\n",
    "            'spend_ooh':'ooh'\n",
    "    }\n",
    "\n",
    "loader = load.DataFrameDataLoader(\n",
    "    df=df, # Attention, le csv doit être au même endroit que le script python\n",
    "    kpi_type='non_revenue',\n",
    "    coord_to_columns=coord_to_columns,\n",
    "    media_to_channel=media_to_channel,\n",
    "    media_spend_to_channel=media_spend_to_channel,\n",
    "    reach_to_channel=reach_to_channel,\n",
    "    frequency_to_channel= frequency_to_channel,\n",
    "    rf_spend_to_channel= rf_spend_to_channel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latence et saturation des canaux média  |  Meridian  |  Google for Developers\n",
    "alpha_prior = tfp.distributions.Uniform(\n",
    "low= [0.0001, 0.0001, 0.0001, 0.0001, 0.0001,0.0001],\n",
    "high=[0.4, 0.3, 0.3, 0.6, 0.3, 0.4],\n",
    "name=constants.ALPHA_M\n",
    ")\n",
    "\n",
    "# Elasticité cumulée, ie expected per euro spent during the period\n",
    "ec_priors = tfp.distributions.TruncatedNormal(\n",
    "    loc= [0.1, 0.2, 0.2,0.3, 0.4, 0.2],\n",
    "    scale=[2.0, 2.0, 2.0, 2.0, 2.0, 2.0],\n",
    "    low = 0.001,\n",
    "    high= 10.0,\n",
    "    name=constants.EC_M\n",
    ")\n",
    "\n",
    "# Intensity of media effect\n",
    "# Google → strong direct effet, TV → harder to measure its effect through time\n",
    "beta_prior = tfp.distributions.LogNormal(\n",
    "    loc= [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "scale=[0.17, 0.2, 0.2, 0.13, 0.17, 0.17]\n",
    ", # pour jouer sur l'incertitude\n",
    "    name=constants.BETA_M\n",
    ")\n",
    "\n",
    "alpha_prior_rf = tfp.distributions.Uniform(\n",
    "low= [0.5, 0.5, 0.001],\n",
    "high=[1.0, 1.0, 0.7],\n",
    "name=constants.ALPHA_M\n",
    ")\n",
    "\n",
    "ec_priors_rf = tfp.distributions.TruncatedNormal(\n",
    "    loc= [0.4, 0.4, 0.3],\n",
    "    scale=[2.0, 2.0, 2.0],\n",
    "    low = 0.001,\n",
    "    high= 10.0,\n",
    "    name=constants.EC_M\n",
    ")\n",
    "\n",
    "beta_prior_rf = tfp.distributions.LogNormal(\n",
    "    loc= [0.0, 0.0, 0.0],\n",
    "scale=[0.095, 0.09, 0.11]\n",
    ", # pour jouer sur l'incertitude\n",
    "    name=constants.BETA_M\n",
    ")\n",
    "\n",
    "knot_prior = tfp.distributions.Normal(\n",
    "    loc = 0.0,\n",
    "    scale = 0.2,\n",
    "    name=constants.KNOT_VALUES)\n",
    "# How much the baseline of each geo is allowed to changed compared to the one with the most population\n",
    "baseline_prior = tfp.distributions.Normal(\n",
    "\t\tloc = 0.0,\n",
    "\t\tscale = 0.01,\n",
    "\t\tname = constants.BASELINE_GEO\n",
    ")\n",
    "prior = prior_distribution.PriorDistribution(\n",
    "    knot_values=knot_prior,\n",
    "    tau_g_excl_baseline=baseline_prior,\n",
    "    alpha_m=alpha_prior,\n",
    "    alpha_rf = alpha_prior_rf,\n",
    "    beta_m=beta_prior,\n",
    "    beta_rf = beta_prior_rf,\n",
    "    ec_m=ec_priors,\n",
    "    ec_rf = ec_priors_rf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_spec = spec.ModelSpec(knots = 20,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tprior=prior,\n",
    "                            media_prior_type='coefficient',\n",
    "                            rf_prior_type = 'coefficient',\n",
    "                            baseline_geo = None,\n",
    "                            max_lag= 18)\n",
    "\n",
    "mmm =model.Meridian(\n",
    "    input_data=df,\n",
    "    model_spec=model_spec\n",
    ")\n",
    "\n",
    "mmm.sample_prior(500)\n",
    "mmm.sample_posterior(n_chains=10, n_adapt=2000, n_burnin=500, n_keep=1000, seed=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
